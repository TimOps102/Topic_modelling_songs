{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad9cb8d",
   "metadata": {},
   "source": [
    "# Cooccurrences\n",
    "\n",
    "Cooccurrences are word forms that appear significantly frequently together. In other words: If one of the words in a cooccurring pair appears in a sentence it is very likely to also find the other one.\n",
    "\n",
    "Watch the additional material on cooccurrences. \n",
    "\n",
    "Your have the following corpus of seven sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57f946",
   "metadata": {},
   "source": [
    "```\n",
    "\"The dog plays.\",\n",
    "\"The child plays.\",\n",
    "\"The moon and the sun are shining.\",\n",
    "\"The sun is burning\",\n",
    "\"The fire is burning\",\n",
    "\"The moon is shining\",\n",
    "\"The candle is burning and shining\",\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb57e9ab",
   "metadata": {},
   "source": [
    "### Document Term Matrix and Term-Term Matrix\n",
    "1) Use this to build a document term matrix and then a term-term-matrix. You can consider `all`, `the`, `with`, `and`, `are`,  and `is`  stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918be6c",
   "metadata": {},
   "source": [
    "### Cooccurrences\n",
    "2) Calculate the DICE-coefficient for (`sun` and `shining`)  and for (`moon` and `shining`) and (`sun` and `moon`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c931a9",
   "metadata": {},
   "source": [
    "3) We can use the Term-Term matrix and the cosine similarity to determine a semantic distance of two words. Each word is represented as the vector of its cooccurring words. calculate the semantic similarity of `sun`, `moon` and `shining`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bc31a",
   "metadata": {},
   "source": [
    "4) The following top 14 words occurring in the same sentence as the words \"Forschende\", \"Wissenschaftlerin\", \"Wissenschaflter\" and \"Politikerin\" following the Wortschatz Portal are:\n",
    "\n",
    "```\n",
    "Forschende: haben (707), Universität (686), ETH (555), Zürich (372), Universität Bern (350), herausgefunden (327), ETH Zürich (314), Bern (276), Fachmagazin (208), Uni (201), Studierende (200), berichten (178), Max-Planck-Institut (167), Universität Zürich (167),\n",
    "\n",
    "Wissenschaftlerin: die (364), Universität (217), sagt (137), Die (132), leitende (127), erklärt (123), Priesemann (121), forscht (118), eine (116), als (99), Thi (93), Viola Priesemann (92), Hilde Mangold (91), Max-Planck-Institut (88),\n",
    "\n",
    "Wissenschaftler: Wissenschaftlerinnen (6,130), haben (3,945), Universität (3,263), Studie (3,008), die (2,996), dass (2,174), forschen (1,777), berichten (1,562), herausgefunden (1,545), untersuchten (1,490), Politiker (1,474), der (1,461), untersuchen (1,446), University (1,416)\n",
    "\n",
    "\n",
    "Politikerin: die (1,185), Die (510), parteilose (507), sagte (482), eine (375), als (368), sie (367), beliebteste (333), Partei (300), Politiker (293), konservative (280), grüne (237), sozialistische (219), Wagenknecht (217), \n",
    "```\n",
    "\n",
    "Calculate the semantic distance between these words using the cosine distance. Explain what you see.\n",
    "\n",
    "**Note**: Multi word units are considered one entry in the vocabulary, e.g. \"ETH Zürich\" is one unit and is different from \"ETH\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
