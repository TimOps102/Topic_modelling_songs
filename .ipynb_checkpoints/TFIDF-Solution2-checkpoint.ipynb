{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c672af5",
   "metadata": {},
   "source": [
    "# TF-IDF Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333f8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d5dae3",
   "metadata": {},
   "source": [
    "You have the following (tokenized) document collection:\n",
    "\n",
    "|id | words|\n",
    "|---|------|\n",
    "| 1 | aunt, aunt, uncle, like, cake|\n",
    "| 2 | uncle, like, cake|\n",
    "| 3 | cake, taste, sweet|\n",
    "| 4 | aunt, sweet, like|\n",
    "| 5| cake, cake, bake, uncle, sweet|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e743b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0f2bfc7",
   "metadata": {},
   "source": [
    "1. Determine the Document Term Matrix.\n",
    "\n",
    "2. Calculate all the TFIDF values. (For simplicity: Use the document frequency tf - unnormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6f256f",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "Document Term Matrix:\n",
    "\n",
    "Tf IDF Values:\n",
    "\n",
    "| term |  D1| D2|D3|D4|D5| IDF|\n",
    "|------|----|---|--|--|--|---|\n",
    "| aunt| 2|0|0|1|0|0.9162907|\n",
    "| uncle|1|1|0|0|1|0.5108256| \n",
    "| like|1|1|0|1|0|0.5108256| \n",
    "| cake|1|1|1|0|2|0.2231436|\n",
    "| taste|0|0|1|0|0|1.609438|\n",
    "| sweet|0|0|1|1|1|0.5108256|\n",
    "| bake|0|0|0|0|1|1.609438|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tf-IDF Values:\n",
    "\n",
    "| term |  D1| D2|D3|D4|D5|\n",
    "|------|----|---|--|--|--|\n",
    "| aunt|1.832581 |0|0|0.9162907|0|\n",
    "| uncle|0.5108256|0.5108256|0|0|0.5108256| \n",
    "| like|0.5108256|0.5108256|0|0.5108256|0| \n",
    "| cake|0.2231436|0.2231436|0.2231436|0|0.4462872|\n",
    "| taste|0|0|1.609438|0|0|\n",
    "| sweet|0|0|0.5108256|0.5108256|0.5108256|\n",
    "| bake|0|0|0|0|1.609438|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520816d",
   "metadata": {},
   "source": [
    "# A2 - Application Retrieval\n",
    "\n",
    "We can use the tf-idf table to determine the similarity of two documents. Each document can be represented as the vector of its tfidf weighted words. The cosine of the two vectors is often used to calculate a similarity measure.\n",
    "\n",
    "When for example a user searches for \"car insurance\", you can interpret the query as a new document and translate the query into a vector corresponding to your vocabulary. Calculate the cosine similarity with every document in your corpus and  return the best match.\n",
    "\n",
    "$$ cos(\\vec{q},\\vec{d}) = \\frac{\\vec{q}\\cdot\\vec{d}}{\\lVert\\vec{q}\\rVert\\cdot\\lVert\\vec{d}\\rVert}$$\n",
    "\n",
    "\n",
    "\n",
    "Which document would the queries $Q_1=[uncle, aunt, like]$ and $Q_2=[uncle, aunt, cake]$ return?\n",
    "\n",
    "(To generate a query vector, create a vector that has the same dimension as the vocabulary and 1 when a word occurs in the query and zero everywhere else.)\n",
    "\n",
    "Consider document set ($D_1$, $D_4$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770b91b",
   "metadata": {},
   "source": [
    "### Solution\n",
    "\n",
    "$\\vec{Q_1} = (1,1,1,0,0,0,0)^T \\rightarrow \\vec{Q_1} = (0.9162907,0.5108256,0.5108256,0,0,0,0)^T$\n",
    "\n",
    "$\\vec{Q_2} = (1,1,0,1,0,0,0)^T \\rightarrow \\vec{Q_2} = (0.9162907,0.5108256,0,0.2231436,0,0,0)^T$\n",
    "\n",
    "$\\vec{D_1} = (1.832581,0.5108256,0.5108256,0.2231436,0,0,0)$\n",
    "\n",
    "$\\vec{D_4} = (1.832581,0,0.5108256,0,0,0.5108256,0)$\t     \n",
    "\n",
    "Similarities :\n",
    "\n",
    "\n",
    "\n",
    "|| D1| D4|\n",
    "|----|---|---|\n",
    "|Q1| 0.9515| 0.8387 |\n",
    "|Q2| 0.9358|0.7947\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97bcdb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9515456611591128\n",
      "0.8441013501317292\n",
      "0.9358921958561208\n",
      "0.7947985208409508\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "q1 = np.array((0.9162907,0.5108256,0.5108256,0,0,0,0))\n",
    "q2 = np.array((0.9162907,0.5108256,0,0.2231436,0,0,0))\n",
    "d1 = np.array((1.832581,0.5108256,0.5108256,0.2231436,0,0,0))\n",
    "d2 = np.array((1.832581,0,0.5108256,0.,0,0.5108256,0))\n",
    "\n",
    "print(q1@d1 / np.linalg.norm(q1)/ np.linalg.norm(d1))\n",
    "print(q1@d2 / np.linalg.norm(q1)/ np.linalg.norm(d2))\n",
    "print(q2@d1 / np.linalg.norm(q2)/ np.linalg.norm(d1))\n",
    "print(q2@d2 / np.linalg.norm(q2)/ np.linalg.norm(d2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
