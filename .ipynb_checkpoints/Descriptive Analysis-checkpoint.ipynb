{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "28f76d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('german')\n",
    "nlp = spacy.load('de_core_news_md',disable = ['parser','ner'])\n",
    "nlp.max_length = 3000000\n",
    "punctuation = string.punctuation+\"’``''‘...\"\n",
    "\n",
    "\n",
    "csv_file_path = \"songs_with_topic.csv\"\n",
    "df = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b1eced26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~’``\\'\\'‘...'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "89bcc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddr_texts = df[df[\"Category\"]==\"DDR\"]\n",
    "ddr_texts = [nltk.sent_tokenize(x) for x in ddr_texts[\"Text\"]]\n",
    "ddr_texts = \" \".join(sum(ddr_texts,[]))\n",
    "\n",
    "brd_texts = df[df[\"Category\"]==\"BRD\"]\n",
    "brd_texts = [nltk.sent_tokenize(x) for x in brd_texts[\"Text\"]]\n",
    "brd_texts = \" \".join(sum(brd_texts,[]))\n",
    "\n",
    "compare = \"\"\n",
    "with open('news_1995.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        index, sentence = line.strip().split('\\t', 1)\n",
    "        compare += sentence +\" \"\n",
    "\n",
    "songs = {\"DDR\": ddr_texts, \"BRD\": brd_texts, \"Compare\": compare}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a101d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "297c9f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR Tokens mit Stopwörtern: 156218\n",
      "BRD Tokens mit Stopwörtern: 170080\n",
      "Compare Tokens mit Stopwörtern: 151261\n"
     ]
    }
   ],
   "source": [
    "unigrams={}\n",
    "for k,v in songs.items():\n",
    "    count = 0\n",
    "    doc = nlp(v)\n",
    "    words = [x.lemma_ if not x.is_punct else str(x) for x in doc]\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in punctuation]\n",
    "    words = [word for word in words if len(word)>2]\n",
    "    count = len(words)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    unigrams[k] = words\n",
    "    print(f\"{k} Tokens mit Stopwörtern: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b7b481",
   "metadata": {},
   "source": [
    "# Anzahl der Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cec550ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR Tokens ohne Stopwörter:  79404\n",
      "BRD Tokens ohne Stopwörter:  87085\n",
      "Vergleichskorpus Tokens ohne Stopwörter:  88528\n"
     ]
    }
   ],
   "source": [
    "print(\"DDR Tokens ohne Stopwörter: \", len(unigrams[\"DDR\"]))\n",
    "print(\"BRD Tokens ohne Stopwörter: \", len(unigrams[\"BRD\"]))\n",
    "print(\"Vergleichskorpus Tokens ohne Stopwörter: \", len(unigrams[\"Compare\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e31897",
   "metadata": {},
   "source": [
    "# Most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "443d2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(tokens,n):    \n",
    "    word_freq = Counter(tokens)\n",
    "    top_words = word_freq.most_common(n)\n",
    "    table_data = pd.DataFrame(top_words, columns=['Word', 'Frequency'])\n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b9d4379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gehen</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liebe</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mehr</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sagen</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>immer</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kommen</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nie</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>leben</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ganz</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>schon</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Frequency\n",
       "0   gehen        822\n",
       "1   liebe        820\n",
       "2    mehr        745\n",
       "3   sagen        714\n",
       "4   immer        693\n",
       "5  kommen        688\n",
       "6     nie        643\n",
       "7   leben        629\n",
       "8    ganz        618\n",
       "9   schon        606"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent(unigrams[\"BRD\"], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a1b30",
   "metadata": {},
   "source": [
    "# Type/Token Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9f86b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_token(tokens):\n",
    "    word_freq = Counter(tokens)\n",
    "    return len(word_freq.keys())/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "159bea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTR for DDR:  0.1379579503965756\n",
      "TTR for BRD:  0.12362955904806731\n"
     ]
    }
   ],
   "source": [
    "print(\"TTR for DDR: \", type_token(unigrams[\"DDR\"]))\n",
    "print(\"TTR for BRD: \", type_token(unigrams[\"BRD\"]))\n",
    "\n",
    "#ist recht niedrig weil in Songs viele Refrains vorkommen und sich Wörter wiederholen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7732b4a9",
   "metadata": {},
   "source": [
    "# Most frequent bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9cebe561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd61510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams={}\n",
    "for k,v in songs.items():\n",
    "    words = word_tokenize(v.lower())\n",
    "    words = [word for word in words if word not in punctuation and word not in stopwords]\n",
    "    bi_grams = list(ngrams(words, 2))\n",
    "    bigrams[k] = bi_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f893ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(la, la)</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(bum, bum)</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(oh, oh)</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(nie, mehr)</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(na, na)</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(tanz, tanz)</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(liebe, liebe)</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(hey, hey)</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(ja, ja)</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(tag, nacht)</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(ganz, allein)</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(gibt, s)</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(feuer, flamme)</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(tut, gut)</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(herz, klopft)</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(hmm, hmm)</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(ha, ha)</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(bum, immer)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(immer, bum)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(bum, herz)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(klopft, bum)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(ba, ba)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(gut, tut)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(geld, geld)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(flamme, feuer)</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(heut, nacht)</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(nein, nein)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(liebte, mädchen)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(geh, n)</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(geht, s)</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(weiß, genau)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(tuut, tuut)</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(ho, ho)</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(seh, n)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>(fahren, fahren)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>(amadeus, amadeus)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>(lieb, liebst)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>(fütter, ego)</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>(amore, mio)</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>(fata, morgana)</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Frequency\n",
       "0             (la, la)        430\n",
       "1           (bum, bum)        280\n",
       "2             (oh, oh)        192\n",
       "3          (nie, mehr)        122\n",
       "4             (na, na)         91\n",
       "5         (tanz, tanz)         86\n",
       "6       (liebe, liebe)         82\n",
       "7           (hey, hey)         77\n",
       "8             (ja, ja)         75\n",
       "9         (tag, nacht)         61\n",
       "10      (ganz, allein)         61\n",
       "11           (gibt, s)         57\n",
       "12     (feuer, flamme)         55\n",
       "13          (tut, gut)         50\n",
       "14      (herz, klopft)         47\n",
       "15          (hmm, hmm)         46\n",
       "16            (ha, ha)         46\n",
       "17        (bum, immer)         44\n",
       "18        (immer, bum)         44\n",
       "19         (bum, herz)         44\n",
       "20       (klopft, bum)         44\n",
       "21            (ba, ba)         44\n",
       "22          (gut, tut)         40\n",
       "23        (geld, geld)         40\n",
       "24     (flamme, feuer)         39\n",
       "25       (heut, nacht)         38\n",
       "26        (nein, nein)         37\n",
       "27   (liebte, mädchen)         37\n",
       "28            (geh, n)         36\n",
       "29           (geht, s)         36\n",
       "30       (weiß, genau)         34\n",
       "31        (tuut, tuut)         34\n",
       "32            (ho, ho)         33\n",
       "33            (seh, n)         32\n",
       "34    (fahren, fahren)         32\n",
       "35  (amadeus, amadeus)         32\n",
       "36      (lieb, liebst)         32\n",
       "37       (fütter, ego)         32\n",
       "38        (amore, mio)         31\n",
       "39     (fata, morgana)         29"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent(bigrams[\"BRD\"], 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c23a4b0",
   "metadata": {},
   "source": [
    "# LLR Keyness Analysis with a Compare Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7440a762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDR Tokens mit Stopwörtern: 30047\n",
      "BRD Tokens mit Stopwörtern: 28596\n",
      "Compare Tokens mit Stopwörtern: 38257\n"
     ]
    }
   ],
   "source": [
    "unigrams={}\n",
    "for k,v in songs.items():\n",
    "    allowed_postags=['NOUN']\n",
    "    count = 0\n",
    "    doc = nlp(v)\n",
    "    words = [x.lemma_ if not x.is_punct else str(x) for x in doc]\n",
    "    words = [x.lemma_ for x in doc if x.pos_ in allowed_postags]\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in punctuation]\n",
    "    words = [word for word in words if len(word)>2]\n",
    "    count = len(words)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "    unigrams[k] = words\n",
    "    print(f\"{k} Tokens mit Stopwörtern: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5da02442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 9 29768 38187 156.38549039805753 200.61450960194247\n",
      "Keynesss Scores for DDR\n",
      "nacht \t 600.2940742635931\n",
      "liebe \t 500.8404948583806\n",
      "traum \t 435.87080002869175\n",
      "lied \t 377.30782729069745\n",
      "welt \t 376.8727790217197\n",
      "leben \t 312.6323251483785\n",
      "tag \t 308.25923386617114\n",
      "erde \t 264.1637696305394\n",
      "wind \t 249.59463451226338\n",
      "stein \t 221.47254614052179\n",
      "zeit \t 220.53670881178536\n",
      "herz \t 216.462536206722\n",
      "mark \t 207.15362734749172\n",
      "auge \t 206.2265238469129\n",
      "sonne \t 200.02447302789545\n",
      "haut \t 188.88911690719272\n",
      "million \t 183.08857219241696\n",
      "stern \t 178.09300371055593\n",
      "hand \t 176.15195833263613\n",
      "rock \t 171.9083777980035\n",
      "eis \t 161.53997455952918\n",
      "glück \t 159.1984464285373\n",
      "himmel \t 149.3451589315859\n",
      "gesicht \t 146.14077961368878\n",
      "mädchen \t 138.38903565876905\n",
      "sehnsucht \t 138.03996264682155\n",
      "freund \t 131.66497243970292\n",
      "meer \t 126.27580246725881\n",
      "kind \t 125.54815396666257\n",
      "wort \t 125.29314444043769\n",
      "blut \t 122.3570909050978\n",
      "haus \t 121.25940018460312\n",
      "fieber \t 118.85928917227046\n",
      "licht \t 118.80091007149119\n",
      "morgen \t 118.76634952179671\n",
      "mensch \t 116.8641982052718\n",
      "feuer \t 115.4444141198613\n",
      "blume \t 109.71237471077816\n",
      "träne \t 107.82178826880111\n",
      "mond \t 104.57688369330586\n",
      "\n",
      "\n",
      "\n",
      "817 9 28377 38187 352.1333153055706 473.8666846944294\n",
      "Keynesss Scores for BRD\n",
      "liebe \t 1303.8755754479591\n",
      "nacht \t 832.0690547662185\n",
      "herz \t 600.8116354254261\n",
      "welt \t 532.374894839785\n",
      "traum \t 467.1437192656927\n",
      "sonne \t 387.98207062380715\n",
      "mädchen \t 366.2630949309464\n",
      "leben \t 363.04092135965095\n",
      "tag \t 345.9187360431488\n",
      "glück \t 336.64791560436436\n",
      "lied \t 319.46420719763057\n",
      "prozent \t 261.2563591307898\n",
      "zeit \t 228.30150527015883\n",
      "auge \t 228.17389394176232\n",
      "mann \t 226.92373950609127\n",
      "stern \t 220.60902692162918\n",
      "hand \t 220.20038598950072\n",
      "tanz \t 216.51305060224496\n",
      "feuer \t 209.46069442081148\n",
      "himmel \t 205.6890886446624\n",
      "träne \t 200.90379481364795\n",
      "mark \t 181.27120645590884\n",
      "wind \t 177.41032244752265\n",
      "sehnsucht \t 161.384402591701\n",
      "licht \t 149.88560991567658\n",
      "million \t 144.67603489378442\n",
      "sonnenschein \t 143.23426873760837\n",
      "spaß \t 135.34362138473745\n",
      "morgen \t 131.7056121295001\n",
      "haus \t 130.3892493755151\n",
      "freund \t 125.57415844142977\n",
      "erde \t 124.52600181915723\n",
      "rose \t 123.14392706287992\n",
      "angst \t 120.60943841425711\n",
      "wein \t 120.31909286425494\n",
      "wort \t 111.7453946575837\n",
      "meer \t 111.55172347924719\n",
      "tür \t 110.65351418504136\n",
      "mama \t 107.42570155320628\n",
      "haar \t 106.9391673969199\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "import math\n",
    "\n",
    "# Calculate word frequencies\n",
    "for k,v in list(unigrams.items())[:2]:\n",
    "    \n",
    "    comp_freq = FreqDist(unigrams[\"Compare\"])\n",
    "    target_freq = FreqDist(unigrams[k])\n",
    "\n",
    "    # Calculate total word counts\n",
    "    total_comp = len(unigrams[\"Compare\"])\n",
    "    total_target = len(unigrams[k])\n",
    "\n",
    "    # Calculate log-likelihood ratio\n",
    "    keyness_scores = {}\n",
    "    for word in set(unigrams[k]):\n",
    "        \n",
    "        a = target_freq[word]\n",
    "        if word in comp_freq:\n",
    "            b = comp_freq[word]\n",
    "        else:\n",
    "            b = 0\n",
    "        c = total_target\n",
    "        d = total_comp\n",
    "        \n",
    "        E_1 = c*(a+b)/(c+d) + 1e-25\n",
    "        E_2 = d*(a+b)/(c+d) + 1e-25\n",
    "        if word == \"liebe\":\n",
    "            print(a,b,c,d,E_1,E_2)\n",
    "        \n",
    "        LLR = 2 * ((a* math.log(a/E_1 + 1e-25)) + (b * math.log(b/E_2 + 1e-25)))\n",
    "        keyness_scores[word] = LLR\n",
    "\n",
    "    # Sort and rank words based on LLR\n",
    "    sorted_keyness = sorted(keyness_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the top 10 words with highest LLR\n",
    "    print(f\"Keynesss Scores for {k}\")\n",
    "    for word, score in sorted_keyness[:40]:\n",
    "        print(f\"{word} \\t {score}\")\n",
    "    print(\"\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ebc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "songs",
   "language": "python",
   "name": "songs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
