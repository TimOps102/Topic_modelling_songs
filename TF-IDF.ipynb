{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c881a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import spacy\n",
    "import string\n",
    "nlp = spacy.load('de_core_news_md',disable = ['parser','ner'])\n",
    "nlp.max_length = 3100000\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('german')\n",
    "punctuation = string.punctuation+\"’``''‘...\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb5b631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['keyword/brd_sentences.txt', 'keyword/ddr_sentences.txt', 'keyword/news.txt'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = {}\n",
    "with zipfile.ZipFile(\"keywords.zip\") as zfile:\n",
    "    for f in zfile.namelist():\n",
    "        if f != \"keyword/\":\n",
    "            content[f] = zfile.read(f).decode(\"utf8\")\n",
    "content.keys()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce89fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(txt):\n",
    "    doc = nlp(txt)\n",
    "    words = [x.lemma_ if not x.is_punct else str(x) for x in doc]\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in punctuation]\n",
    "    words = [word for word in words if len(word)>2]\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    words = [word for word in words if not word.isdigit()]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "208a0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF:\n",
    "    def create_dtm(self, texts, cut_first=1, min_freq=3):\n",
    "        \n",
    "        # Clean texts\n",
    "        self.texts = {k:preprocess(v) for k,v in texts.items()}\n",
    "        \n",
    "        # Count texts\n",
    "        self.vocab = nltk.FreqDist(sum(self.texts.values(),[]))\n",
    "        \n",
    "        # Prune overall vocabulary\n",
    "        self.vocab = sorted(list(self.vocab.items()),key= lambda x: -x[1]) \n",
    "        self.vocab = [x[0] for x in self.vocab[cut_first:] if x[1] >=min_freq]\n",
    "        \n",
    "        # count and restrict domain level text to the vocabulary\n",
    "        self.term_frequencies = {genre: nltk.FreqDist(text) for genre, text in self.texts.items()}\n",
    "        self.dtm = np.array([[v.get(w,0) for w in self.vocab] for k,v in self.term_frequencies.items()])\n",
    "    \n",
    "    def tfidf(self):\n",
    "        tf = np.log(self.dtm + 1e-25)\n",
    "        #tf = 0.5 + 0.5 * self.dtm / self.dtm.max(-1, keepdims=True) # alternative normalization.\n",
    "        idf = np.log(self.dtm.shape[0] /((da.dtm>0).sum(0) + 1e-25))\n",
    "        return tf * idf\n",
    "\n",
    "    def tfidf_keywords(self, n=10):\n",
    "        \"\"\"Iterate all copora for printing\"\"\"\n",
    "        tfidf = self.tfidf()\n",
    "        return {k:[self.vocab[k] for k in tfidf[i].argsort(0)[::-1][:n]] for i,k in enumerate(self.texts.keys())}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b111d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = TFIDF()\n",
    "da.create_dtm(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef5d799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword/brd_sentences.txt': ['bum',\n",
       "  'tuut',\n",
       "  'dub',\n",
       "  'amadeus',\n",
       "  'hadschi',\n",
       "  'annabelle',\n",
       "  'goodbye',\n",
       "  'tarzan',\n",
       "  'fütter',\n",
       "  'adio',\n",
       "  'knutschfleck',\n",
       "  'morgana',\n",
       "  'fata',\n",
       "  'traumboy',\n",
       "  'nana-nana',\n",
       "  'mamy',\n",
       "  'gianna',\n",
       "  'dudub',\n",
       "  'verdamp',\n",
       "  'golle',\n",
       "  'willem',\n",
       "  'sha',\n",
       "  'holla',\n",
       "  'holadie',\n",
       "  'pan'],\n",
       " 'keyword/ddr_sentences.txt': [\"seh'n\",\n",
       "  \"geh'n\",\n",
       "  \"steh'n\",\n",
       "  \"uns're\",\n",
       "  \"ander'n\",\n",
       "  'kurschatt',\n",
       "  'elfenbein',\n",
       "  \"versteh'n\",\n",
       "  'gradaus',\n",
       "  'traumzeit',\n",
       "  'superfrau',\n",
       "  'drache',\n",
       "  \"and're\",\n",
       "  'immerfort',\n",
       "  'nebelmeer',\n",
       "  \"wenn's\",\n",
       "  \"geseh'n\",\n",
       "  \"zieh'n\",\n",
       "  'weltenmeer',\n",
       "  \"bist'n\",\n",
       "  \"über's\",\n",
       "  'lebensroulette',\n",
       "  'susan',\n",
       "  'gojko',\n",
       "  'arbeitsschluss'],\n",
       " 'keyword/news.txt': ['euro',\n",
       "  'unternehmen',\n",
       "  'trump',\n",
       "  'team',\n",
       "  'politisch',\n",
       "  'mehrere',\n",
       "  'regierung',\n",
       "  'pro',\n",
       "  'europäisch',\n",
       "  'aktie',\n",
       "  'zunächst',\n",
       "  'ehemalig',\n",
       "  'angabe',\n",
       "  'saison',\n",
       "  'betonen',\n",
       "  'bislang',\n",
       "  'entsprechend',\n",
       "  'zufolge',\n",
       "  'schweiz',\n",
       "  'mitarbeiter',\n",
       "  'unterstützen',\n",
       "  'entwickeln',\n",
       "  'bestätigen',\n",
       "  'information',\n",
       "  'befinden']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.tfidf_keywords(n=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "songs",
   "language": "python",
   "name": "songs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
